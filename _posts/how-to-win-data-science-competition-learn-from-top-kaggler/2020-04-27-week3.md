---
layout: post
title: Week 3
---

## WEEK 3

### Metric optimization

- Regression metric:
  - MSE, RMSE, R-squared
  [](/how-to-win-data-science-competition-learn-from-top-kaggler/images/R_square_metric.png)
  - MAE is more robust, less sensitive with outliers than MSE. If unexpected values should be cared, then use MSE.
  - (R)MSPE (Mean Squared Percentage Error), MAPE (Mean Absolute Percentage Error)
  [](/how-to-win-data-science-competition-learn-from-top-kaggler/images/mspe_mape.png)
  - (R)MSLE (Root Mean Square Logarithmic Error)
  [](/how-to-win-data-science-competition-learn-from-top-kaggler/images/rmsle_metric.png)

--> MSE, RMSE prone to mean value of target variable; MAE prone to median value of target variable; (R)MSPE prone to weighted (1/y_i) mean value of target variable; MAPE prone to weighted (1/y_i) median value of target variable; (R)MSLE prone to mean value of target variable in logarithms space (which lead to more robust with outlier than MSE, RMSE).

- Classification metric
  - Accuracy: prone to most frequent value of target variable (most frequent class).
  - AUC
  - logloss (cross-entropy)
  - [Cohen's (Quadratic weighted) Kappa](https://www.coursera.org/learn/competitive-data-science/lecture/EhJzY/classification-metrics-review): Commonly use on kaggle competition.
    
  
  
  
  
  
  
  
