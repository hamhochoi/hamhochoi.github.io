---
layout: post
title: "Week 5"
---

## WEEK 5: Image Segmentation

- Hough Transform: Line detection
- Ostu algorithms: 
  - Seperate background and foreground by using threshold to move part of histogram related to background.
  - Not work if there is much noise, so that histogram of background and foreground aren't seperated. Can handle this case, we can use denoise technique.
  - Assumption: In-class intensity are close, so we can seperate each class by seperate the histogram.
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/ostu_alg.png)
  
  - We try to minimize the weighted variance of ways of seperating the histogram. In which, t: threshold; q(t): probability of class 1 with threshold <=t, by sum up the probabilities of every pixel in this class; p(t): probability of class 2 with threshold >t, by sum up the probabilities of every pixel in this class. 
  - **Note**: If the background is note uniform, we cannot apply the ostu alg because the alg will mislead seperate the different part of the background.
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/ostu_3.png)
    - To handle this problem, we can apply ostu alg to sub-blocks of the image (non-overlapping/overlapping blocks).
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/ostu_4.png)
    
- Interactive Image Segmentation: 
  - Step 1: Ask user to indicate foreground and background. From this information, plot distribution of foreground, background; try to mark pixel have intensity likely with the foreground as foreground, likely with the background as background.  
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_1.png)
  
  - Step 2: 
    - If we just rely on intensity, some pixels in foreground may have intensity closer to background distribution. To handle this issue, we compute weighted geodestic distance: For each pixel, compute the weighted distance between it to the background/foreground indicator (which we ask user to draw, and called 'scrible'), then classify that pixel to the closer class.
    1. Compute the probability for each pixel by the formula in step 1
    2. For each pixel, compute the distance from each pixel to every pixel on the scribles of background and foreground. 
    3. At each pixel, if the smallest cost of going from it to the background > the smallest cost of going from it to foreground --> mark it as background and vice versa.
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_2.png)
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_4.png)
    
  - Step 3: Refine
    - After step 2, we get the boundary of the image. To refine image segmentation alg, we create 'new scrible' base on that boundary: move to inside the boundary a little bit and move to outside the boundary a little bit to get new foreground/background scribble automatically. We also can just refine a sub-region of the boundary to get new scribles. The main idea is if we create scrible close to the boundary, it may have more information about the different between background and foreground.
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_5.png)
    
  - Example: 
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_6.png)
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/img_segment_7.png)
  
- Graph Cuts: (is a part of MS Office!)
  - Each pixel is a node of graph. Create 2 additional nodes: sink node (background) and source node (foreground)
  - Create edges between each node prepresent for a pixel and sink/source node = the probability of each node belong to foreground and background (can get by scribble like 'Interactive Image Segmentation').
  - Create edges between each neighbor nodes. We need 2 nodes close to each other if they both belong to background/foreground and far to each other if one belong to background and one belong to foreground --> use gradient of pixels to become weights of neighbor nodes. 
  - Now we have a graph. To seperate which pixel/node belong to foreground/background, we can use **Min Cut** alg to seperate them.
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/graph_cut_1.png)
  - Example: 
  ![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/graph_cut_2.png)
  
- Mumford-Shah   
  - In segmentation, we want the result close to the original image --> minimize the error
  - At the same time, we don't want the algorithm to copy the original image --> restrict by saying the result shouldn't have much edges --> minimize the penalty. 
  - Is a methodology in which we want to compromise the error of the result (approximation) and the edges (penalty).
  - Not a specific implementation. 
  - It is applied in many other fields beyond the segmentation task.
  
- Activate Contours: [demo](http://demo.ipol.im/demo/g_chan_vese_segmentation/wait?key=08597888E110C5E454CC32FA8F01891F&mu=0.2&action=run)
  - 


### Adobbe Roto Brush: Image Segmentation for video
- Challenges:
  - Overlapping color distribution
  - Week boundaries
  - Topology changes, dynamic backgrounds

- Features:
  - Accuracy
  - Robustness: on diverse data
  - Practical workflow: easy to interact
  - Computational efficiency: > 2 FPS
  
- Algorithms:
  - Localized classifier
  - Multi-frame propagation
  - Local correction
  - Post-processing
  
1. Localized Classifiers
- Assume we have first frame's segmentation (we can do one of above algorithms to get this)
- Create local classifier windows go through the boundary
- Each window, we get the shape prior --> color distribution of background/foreground in this window.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_1.png)
 
- Now, we use above informations of frame T to predict the boundary for frame T+1.
- First, we move windows from frame T to frame T+1. To be correct, we have to estimate the motion of foreground. We can do this by find which region of frame T+1 is closest to each window of frame T (maybe use MSE/RMSE/... to find the closest region/block).
- To adjust the result, we combine information of shape and color distribution of frame T to modified the result **for each window**. 
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_2.png)
- Apply for each window, we get the estimated boundary
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_3.png)
- Apply graph cut, we get the foreground for the frame T+1.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_4.png)

- How to combine the shape & color distribution?
  - If color are seperatable, trust the color
  - If not, trust the shape. The more seperatable the color distribution, the more we use it and the less we use shape infor and vice versa.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_5.png)
  
- Example: 
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_6.png)
  
2. Multi-frame propagation
- To segmentation the frames after the first frame, we shouldn't use the second frame only to predict the foreground of the third frame because it will cause a lot of error. We should also use the first frame (as we trust alot) to predict frames after it.
- We can also use the second frame to adjust it own boundary.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/multiframe_1.png)

3. Local Correction
- If there is some error, we have to let user fix it.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/correction_1.png)

- After user fix it, we want the local region that user fixed should be propagate to the images after this image. So we can use few local window in that region, propagate the changes in these local windows to later images. 
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_2.png)

- Then we have the corrected version.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/localized_classifier_3.png)

4. Post-processing
- Smoothing the boundary: using multiple boundaries of frames to get smoothing.
![](/image_and_video_processing_from_mars_to_hollywood_with_a_stop_at_the_hospital/images/smoothing.png)










  
  
### Reference: 
- [Week 5](https://www.coursera.org/learn/image-processing/lecture/72Ktu/5-otsus-segmentation-with-demo-duration-14-25)
